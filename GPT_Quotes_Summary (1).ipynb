{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxencedubois/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# openai.api_key = # Enter your API KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_data.csv')\n",
    "data_2 = pd.read_csv('your_data.csv')\n",
    "size_answers = 1200\n",
    "sent_call = 120\n",
    "split_sentences = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(text):\n",
    "    return text.replace(\"'\", \"\")\n",
    "\n",
    "def add_backslash(text):\n",
    "    return text.replace(\"'\", \"\\\\'\")\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getquotes(df,sent_call,split_sentences):\n",
    "\n",
    "    if split_sentences == 'Yes':\n",
    "        df['value'] = df['value'].apply(sent_tokenize)\n",
    "        df = df.explode('value').reset_index(drop=True)\n",
    "        df['value'] = df['value'].str.split('- ')  \n",
    "        df = df.explode('value').reset_index(drop=True)\n",
    "    \n",
    "    df = df[df['value'].str.len()>3]\n",
    "    df['value'] = df['value'].apply(remove_apostrophe)\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for value in df['variable'].unique():\n",
    "        new_df = df[df['variable'] == value].copy()\n",
    "        dfs.append(new_df)\n",
    "\n",
    "\n",
    "    output = pd.DataFrame(columns=[\"Question\", \"Best_quote1\", \"Best_quote2\", \"Best_quote3\"])\n",
    "\n",
    "\n",
    "    for df in dfs:\n",
    "\n",
    "        if len(df) > sent_call:\n",
    "\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "            n = len(sent)\n",
    "            sublists = [sent[i:i+sent_call] for i in range(0, n, sent_call)]\n",
    "\n",
    "\n",
    "            q = df['variable'].iloc[0]\n",
    "\n",
    "            quotes = []\n",
    "\n",
    "            for sublist in sublists :\n",
    "\n",
    "                n_sub = len(sublist)\n",
    "\n",
    "                p2 = f\"This is a list of {n_sub} answers to the quesiton '{q}' '{sublist}'. Quote 3 highly representative and interesting answers that provide the most information and add them to a python list list. IMPORTANT : do not change the way the quotes are written, do not add any punctuation. Keep the sentence exactly as it is. The list is the following : \"\n",
    "\n",
    "\n",
    "                response2 = openai.Completion.create(\n",
    "                         model=\"text-davinci-003\",\n",
    "                         prompt=p2,\n",
    "                         temperature=0,\n",
    "                         max_tokens=300,\n",
    "                         top_p=1.0,\n",
    "                         frequency_penalty=0.0,\n",
    "                         presence_penalty=0.0)\n",
    "\n",
    "\n",
    "                text2 = response2['choices'][0]['text'].lstrip()\n",
    "                text2 = str(text2)\n",
    "                text2 = ast.literal_eval(text2)\n",
    "\n",
    "                for i in text2:\n",
    "                    quotes.append(i)\n",
    "\n",
    "            bq1 = random.choice(quotes)\n",
    "            quotes.remove(bq1)\n",
    "\n",
    "            bq2 = random.choice(quotes)\n",
    "            quotes.remove(bq2)\n",
    "\n",
    "            bq3 = random.choice(quotes)\n",
    "\n",
    "            output.loc[len(output)] = [q,bq1, bq2, bq3]\n",
    "\n",
    "        else:\n",
    "\n",
    "            quotes = []\n",
    "\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "\n",
    "            q = df['variable'].iloc[0]\n",
    "\n",
    "            n = len(df)\n",
    "\n",
    "            p2 = f\"This is a list of {n} answers to the quesiton '{q}' '{sent}'. Quote 3 highly representative and interesting answers that provide the most information and add them to a python list list. IMPORTANT : do not change the way the quotes are written, do not add any punctuation. Keep the sentence exactly as it is. The list is the following : \"\n",
    "\n",
    "\n",
    "            response2 = openai.Completion.create(\n",
    "                    model=\"text-davinci-003\",\n",
    "                         prompt=p2,\n",
    "                         temperature=0,\n",
    "                         max_tokens=300,\n",
    "                         top_p=1.0,\n",
    "                         frequency_penalty=0.0,\n",
    "                         presence_penalty=0.0)\n",
    "\n",
    "\n",
    "            text2 = response2['choices'][0]['text'].lstrip()\n",
    "            text2 = str(text2)\n",
    "            text2 = ast.literal_eval(text2)\n",
    "\n",
    "            for i in text2:\n",
    "                    quotes.append(i)          \n",
    "\n",
    "            bq1 = quotes[0]\n",
    "\n",
    "            bq2 = quotes[1]\n",
    "\n",
    "            bq3 = quotes[2]\n",
    "\n",
    "            output.loc[len(output)] = [q, bq1, bq2, bq3]\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsummarry(df,sent_call,size_answers,split_sentences):\n",
    "    \n",
    "    if split_sentences == 'Yes':\n",
    "        df['value'] = df['value'].apply(sent_tokenize)\n",
    "        df = df.explode('value').reset_index(drop=True)\n",
    "        df['value'] = df['value'].str.split('- ')  \n",
    "        df = df.explode('value').reset_index(drop=True)\n",
    "        df = df[df['value'].str.len()>3]\n",
    "        df['value'] = df['value'].apply(remove_apostrophe)\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for value in df['variable'].unique():\n",
    "        new_df = df[df['variable'] == value].copy()\n",
    "        dfs.append(new_df)\n",
    "\n",
    "    \n",
    "    output2 = pd.DataFrame(columns=[\"Question\", \"Summary\"])\n",
    "    \n",
    "    res_max = math.floor(3200/(math.ceil(size_answers / sent_call)))-30\n",
    "\n",
    "\n",
    "    for df in dfs:\n",
    "\n",
    "        if len(df) > sent_call:\n",
    "\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "            n = len(sent)\n",
    "            sublists = [sent[i:i+sent_call] for i in range(0, n, sent_call)]\n",
    "\n",
    "\n",
    "            q = df['variable'].iloc[0]\n",
    "\n",
    "            sumarries = []\n",
    "            \n",
    "\n",
    "            for sublist in sublists :\n",
    "\n",
    "                n_sub = len(sublist)\n",
    "\n",
    "                p = f\" This is a list of {n_sub} answers to the question '{q}'. '{sublist}' Give me thorough detailed analysis of the answers provided. Including examples defending what you highlight as well as the important topics covered. No introduction, no conclusion, only analysis.\"\n",
    "\n",
    "\n",
    "                response = openai.Completion.create(\n",
    "                             model=\"text-davinci-003\",\n",
    "                             prompt=p,\n",
    "                             temperature=0,\n",
    "                             max_tokens=res_max,\n",
    "                             top_p=1.0,\n",
    "                             frequency_penalty=0.0,\n",
    "                             presence_penalty=0.0\n",
    "                            )\n",
    "\n",
    "                text = response['choices'][0]['text'].lstrip()\n",
    "\n",
    "                sumarries.append(text)\n",
    "\n",
    "\n",
    "            n_sum = len(sumarries)\n",
    "\n",
    "            p = f\" This is a list of {n_sum} summaries. Each summary represents an analysis of up to 150 responses to my survey on the question '{q}'.Can you put these '{n}' summaries together to give me a detailed overview of the answers?  The analysis should be detailed, show examples of what you defend, and highlight the major topics covered in the answers.'{sumarries}'\"\n",
    "\n",
    "            response = openai.Completion.create(\n",
    "                    model=\"text-davinci-003\",\n",
    "                        prompt=p,\n",
    "                        temperature=0,\n",
    "                        max_tokens=800,\n",
    "                        top_p=1.0,\n",
    "                        frequency_penalty=0.0,\n",
    "                        presence_penalty=0.0\n",
    "                        )\n",
    "\n",
    "            text = response['choices'][0]['text'].lstrip()\n",
    "\n",
    "            output2.loc[len(output2)] = [q, text]\n",
    "\n",
    "        else:\n",
    "\n",
    "\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "\n",
    "            q = df['variable'].iloc[0]\n",
    "\n",
    "            n = len(df)\n",
    "\n",
    "            p = f\" This is a list of {n} answers to the question '{q}'. '{sent}' Give me thorough detailed analysis of the answers provided. Including examples defending what you highlight as well as the important topics covered.\"    \n",
    "\n",
    "            response = openai.Completion.create(\n",
    "                    model=\"text-davinci-003\",\n",
    "                        prompt=p,\n",
    "                        temperature=0,\n",
    "                        max_tokens=1000,\n",
    "                        top_p=1.0,\n",
    "                        frequency_penalty=0.0,\n",
    "                        presence_penalty=0.0\n",
    "                        )\n",
    "\n",
    "            text = response['choices'][0]['text'].lstrip()\n",
    "\n",
    "            output2.loc[len(output2)] = [q, text]\n",
    "    \n",
    "    \n",
    "    return output2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getResults(data,data_2,sent_call,size_answers,split_sentences): \n",
    "    output = getquotes(data,sent_call,split_sentences)\n",
    "    output2 = getsummarry(data2,sent_call,size_answers,split_sentences)\n",
    "    merged_df = pd.merge(output, output2, on='Question')\n",
    "    merged_df.to_excel('merged_output.xlsx', index=False)\n",
    "    merged_df.to_csv('merged_output.csv', index=False)\n",
    "    \n",
    "    return merged_df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = getResults(data,data_2,sent_call,size_answers,split_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
