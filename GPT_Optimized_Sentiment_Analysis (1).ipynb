{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maxencedubois/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# openai.api_key = # Enter your API KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "size_answers = 1200\n",
    "sent_call = 100 #If split sentences, recommended size = 100, if unsplit recommended size = 50\n",
    "split_sentences = \"No\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(text):\n",
    "    return text.replace(\"'\", \"\")\n",
    "\n",
    "def add_backslash(text):\n",
    "    return text.replace(\"'\", \"\\\\'\")\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(df,sent_call , split_sentences):\n",
    "    \n",
    "    if split_sentences == 'Yes':\n",
    "\n",
    "        df['value'] = df['value'].apply(sent_tokenize)\n",
    "        df = df.explode('value').reset_index(drop=True)\n",
    "        df['value'] = df['value'].str.split('- ')  \n",
    "        \n",
    "    df = df.explode('value').reset_index(drop=True)\n",
    "    df = df[df['value'].str.len()>3]\n",
    "\n",
    "\n",
    "    df['value'] = df['value'].apply(add_backslash)\n",
    "    \n",
    "    output_df = df\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for value in df['variable'].unique():\n",
    "        new_df = df[df['variable'] == value].copy()\n",
    "        dfs.append(new_df)\n",
    "\n",
    "    sentiment_all = []\n",
    "\n",
    "\n",
    "    for df in dfs:\n",
    "\n",
    "        q = df['variable'].iloc[0]\n",
    "\n",
    "        sentiments = [\"Positive\",\"Neutral\", \"Negative\"]\n",
    "\n",
    "        sentiment_q = []\n",
    "\n",
    "        sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "        n = len(sent)\n",
    "        sublists = [sent[i:i+sent_call] for i in range(0, n, sent_call)]\n",
    "\n",
    "        for sublist in sublists:\n",
    "\n",
    "            sentiment_list = []\n",
    "\n",
    "            n_sub = len(sublist)\n",
    "\n",
    "            p = f\"These sentences are answers to the question {q}. Classify the sentiment in these '{n_sub}'sentences '{sublist}' using  these sentiments '{sentiments}'. Use the question as additional context to help find the sentiment. Print me the result for each sentence (just give me the number of the sentence and the corresponding sentiment, don't print the sentence again) \"\n",
    "\n",
    "\n",
    "            response = openai.Completion.create(\n",
    "                                             model=\"text-davinci-003\",\n",
    "                                             prompt=p,\n",
    "                                             max_tokens=500,\n",
    "                                             temperature=0,\n",
    "                                             top_p=1.0,\n",
    "                                             frequency_penalty=0.0,\n",
    "                                             presence_penalty=0.0\n",
    "                                            )\n",
    "\n",
    "            text = response['choices'][0]['text'].lstrip()\n",
    "            lines = text.splitlines()\n",
    "\n",
    "            for line in lines:\n",
    "                if '.' in line:\n",
    "                    sentiment = line.split('. ', 1)[1].strip()\n",
    "                else:\n",
    "                    sentiment = line.split(' ', 1)[1].strip()\n",
    "\n",
    "                sentiment_list.append(sentiment)\n",
    "\n",
    "            sentiment_q.append(sentiment_list)\n",
    "\n",
    "        sentiment_all.append(sentiment_q)\n",
    "\n",
    "    sentiment_all = flatten_list(sentiment_all)\n",
    "    \n",
    "    output_df['sentiment_GPT'] = sentiment_all\n",
    "    \n",
    "    output_df.to_excel('data_sentiment.xlsx', index=False)\n",
    "    output_df.to_csv('data_sentiment.csv', index=False)\n",
    "    \n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = getSentiment(data, sent_call , split_sentences)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
