{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "import nltk\n",
    "import random\n",
    "import re\n",
    "import ast\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "openai.api_key = # Enter your OPEN AI KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "size_answers = 1200\n",
    "sent_call = 100 #If split sentences, recommended size = 100, if unsplit recommended size = 50\n",
    "split_sentences = \"No\"\n",
    "\n",
    "number_questions = 9\n",
    "\n",
    "topic_q1 = [\"Keynote speakers\",\"Breakout sessions\", \"Networking\" , \"The wellbeing space and inclusion\", \"The music and arts\", \"First Nations content\", \"other\"]\n",
    "\n",
    "topic_q2 = [\"Time Management and Organization\",\"Food and Beverage Options\",\"Content of Keynotes and Breakout Sessions\",\"Accessibility\",\"Networking\",\"Facilities\",\"other\"]\n",
    "         \n",
    "topic_q3 = [\"Organization and Logistics\", \"Content\", \"Diversity and Inclusion\", \"other\"]\n",
    "         \n",
    "topic_q4 = [\"Connecting\", \"learn\", \"reflect & celebrate the work of the network\",\"present and share knowledge\", \"other\"]\n",
    "\n",
    "topic_q5 = [\"Networking\",\"Learning\",\"Understanding\", \"other\"]\n",
    "\n",
    "topic_q6 = [\"Looking Forward to the Event\",\"Expressing Gratitude\",\"Networking\",\"Learning New Ideas\"]\n",
    "\n",
    "topic_q7 = [\"inspiring and motivating\", \"disorganized and not particularly useful\", \"need for more structured networking activities\", \"more professional development opportunities and in-depth discussions\" , \"more research to be presented / more failure stories to be shared / more diverse opportunities\" , \"more space to absorb the information presented / more shorter breaks.\" , \"more space for networking\" , \"more advice on handling burnout and overextending oneself\", \"more visibility and representation of First Nations people\", \"more shared learnings between clinicians and between youth engagements\",\"other\"]\n",
    "\n",
    "topic_q8 = [\"Other\"] # For theses questions it is easier to just read through\n",
    "\n",
    "topic_q9 = [\"Other\"]  # For theses questions it is easier to just read through\n",
    "\n",
    "all_topics= [topic_q1, topic_q2, topic_q3, topic_q4, topic_q5, topic_q6, topic_q7, topic_q8, topic_q9]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Defining functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(text):\n",
    "    return text.replace(\"'\", \"\")\n",
    "\n",
    "def add_backslash(text):\n",
    "    return text.replace(\"'\", \"\\\\'\")\n",
    "\n",
    "def flatten_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics(data, all_topics, sent_call , split_sentences):\n",
    "    \n",
    "    if split_sentences == 'Yes':\n",
    "        data['value'] = data['value'].apply(sent_tokenize)\n",
    "        data = data.explode('value').reset_index(drop=True)\n",
    "        data['value'] = data['value'].str.split('- ')\n",
    "        data = data.explode('value').reset_index(drop=True)\n",
    "\n",
    "    data = data[data['value'].str.len() > 3]\n",
    "    data['value'] = data['value'].apply(add_backslash)\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    for value in data['variable'].unique():\n",
    "        new_df = data[data['variable'] == value].copy()\n",
    "        dfs.append(new_df)\n",
    "\n",
    "    final_topics = []\n",
    "\n",
    "    for i in range(len(dfs)):\n",
    "        df = dfs[i]\n",
    "        topics = all_topics[i]\n",
    "        q = dfs[0]['variable']\n",
    "        topics_output = []\n",
    "\n",
    "        if len(df) > sent_call:\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "            n = len(sent)\n",
    "            sublists = [sent[i:i + sent_call] for i in range(0, n, sent_call)]\n",
    "\n",
    "            for sublist in sublists:\n",
    "                n_sub = len(sublist)\n",
    "                p = f\"Classify the topics in these '{n_sub}' sentences '{sublist}' using these topics '{topics}'. Print me the result for each sentence (just give me the number of the sentence and the corresponding topic, don't print the sentence again)\"\n",
    "\n",
    "                response = openai.Completion.create(\n",
    "                        model=\"text-davinci-003\",\n",
    "                        prompt=p,\n",
    "                        max_tokens=800,\n",
    "                        temperature=0,\n",
    "                        top_p=1.0,\n",
    "                        frequency_penalty=0.0,\n",
    "                        presence_penalty=0.0\n",
    "                    )\n",
    "\n",
    "                text = response['choices'][0]['text'].lstrip()\n",
    "                lines = text.splitlines()\n",
    "                topic_list = [line.split('. ', 1)[1].strip() for line in lines]\n",
    "\n",
    "                for i in topic_list:\n",
    "                    topics_output.append(i)\n",
    "\n",
    "                # Introduce a pause of 2 seconds before making the next API call\n",
    "                time.sleep(2)\n",
    "\n",
    "        else:\n",
    "            sent = [f\"{index + 1}. {sentence}\" for index, sentence in enumerate(df['value'])]\n",
    "            n = len(sent)\n",
    "            p = f\"Classify the topics in these '{n}' sentences '{sent}' using these topics '{topics}'. Print me the result for each sentence (just give me the number of the sentence and the corresponding topic, don't print the sentence again)\"\n",
    "\n",
    "            response = openai.Completion.create(\n",
    "                model=\"text-davinci-003\",\n",
    "                prompt=p,\n",
    "                max_tokens=1500,\n",
    "                temperature=0,\n",
    "                top_p=1.0,\n",
    "                frequency_penalty=0.0,\n",
    "                presence_penalty=0.0\n",
    "                )\n",
    "\n",
    "            text = response['choices'][0]['text'].lstrip()\n",
    "            lines = text.splitlines()\n",
    "            print()\n",
    "            topic_list = [line.split('. ', 1)[1].strip() for line in lines if len(line.split('. ', 1)) > 1]\n",
    "            for i in topic_list:\n",
    "                topics_output.append(i)\n",
    "\n",
    "                # Introduce a pause of 2 seconds before making the next API call\n",
    "            time.sleep(2)\n",
    "\n",
    "        final_topics.append(topics_output)\n",
    "        final_topics = flatten_list(final_topics)\n",
    "\n",
    "\n",
    "\n",
    "    data[\"GPT_topics\"] = final_topics\n",
    "    data.to_excel('data_topics.xlsx', index=False)\n",
    "    data.to_csv('data_topics.csv', index=False)\n",
    "    \n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = get_topics(data, all_topics, sent_call , split_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
